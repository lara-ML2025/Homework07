{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QshK8s21WBrf"
   },
   "source": [
    "# Homework07\n",
    "\n",
    "Exercises to practice pandas, data analysis and regression\n",
    "\n",
    "## Goals\n",
    "\n",
    "- Understand the effects of pre-processing data\n",
    "- Get familiar with the ML flow: encode -> normalize -> train -> evaluate\n",
    "- Understand the difference between regression and classification tasks\n",
    "- Build intuition for different regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Hf8SXUwWOho"
   },
   "source": [
    "### Setup\n",
    "\n",
    "Run the following 2 cells to import all necessary libraries and helpers for this homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/PSAM-5020-2025F-A/5020-utils/raw/main/src/data_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "\n",
    "from data_utils import object_from_json_url\n",
    "from data_utils import regression_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "\n",
    "Let's load up the full [ANSUR](https://www.openlab.psu.edu/ansur2/) dataset that we looked at briefly in [Week 02](https://github.com/DM-GY-9103-2024F-H/WK02).\n",
    "\n",
    "This is the dataset that has anthropometric information about U.S. Army personnel.\n",
    "\n",
    "#### WARNING\n",
    "\n",
    "Like we mentioned in class, this dataset is being used for these exercises due to the level of detail in the dataset and the rigorous process that was used in collecting the data.\n",
    "\n",
    "This is a very specific dataset and should not be used to draw general conclusions about people, bodies, or anything else that is not related to the distribution of physical features of U.S. Army personnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "ANSUR_FILE = \"https://raw.githubusercontent.com/PSAM-5020-2025F-A/5020-utils/main/datasets/json/ansur.json\"\n",
    "ansur_data = object_from_json_url(ANSUR_FILE)\n",
    "\n",
    "# Look at first 2 records\n",
    "ansur_data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nested data\n",
    "\n",
    "This is that *nested* dataset from Week 02.\n",
    "\n",
    "# ðŸ¤”\n",
    "\n",
    "Let's load it into a `DataFrame` to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read into DataFrame\n",
    "ansur_df = pd.DataFrame.from_records(ansur_data)\n",
    "ansur_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ˜“ðŸ™„\n",
    "\n",
    "That didn't work too well. We ended up with objects in our columns.\n",
    "\n",
    "Luckily, our `DataFrame` library has a function called [`json_normalize()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.json_normalize.html) that can help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read into DataFrame\n",
    "ansur_df = pd.json_normalize(ansur_data)\n",
    "ansur_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better. `DataFrames` are magic.\n",
    "\n",
    "#### Data Exploration\n",
    "\n",
    "Before we start creating models, let's do a little bit of data analysis and get a feeling for the shapes, distributions and relationships of our data.\n",
    "\n",
    "1. Print `min`, `max` and `average` values for all of the features.\n",
    "2. Print `covariance` tables for `age`, `ear.length` and `head.circumference`.\n",
    "3. Plot `age`, `ear.length` and `head.circumference` versus the $1$ *feature* that is most correlated to each of them.\n",
    "\n",
    "Don't forget to *encode* and *normalize* the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Work on Data Exploration here\n",
    "\n",
    "### Encode non-numerical features\n",
    "# gender is non-numerical and has two possible values: F and M\n",
    "# since the values don't have an order, we can use OneHotEncoder, which turns each value into a distinct feature and uses 0 and 1 to mark whether a record has a value or not\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ansur_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "gender_encoded = ansur_encoder.fit_transform(ansur_df[['gender']])\n",
    "# getting the new column names\n",
    "# since ansur_encoder.categories creates a list of arrays (one array per feature), we access the first element of the list\n",
    "new_col_names = ansur_encoder.categories_[0]\n",
    "ansur_encoded_gender_df = pd.DataFrame(gender_encoded, columns=new_col_names, index=ansur_df.index)\n",
    "\n",
    "# concatenating the new columns to the original dataframe and dropping the original gender column\n",
    "ansur_encoded_df = pd.concat([ansur_df, ansur_encoded_gender_df], axis=1)\n",
    "ansur_encoded_df = ansur_encoded_df.drop(columns=['gender'])\n",
    "\n",
    "# checking the new dataframe and confirming is has been encoded correctly\n",
    "# print(ansur_encoded_df.head())\n",
    "\n",
    "\n",
    "## 1. Print min, max, avg\n",
    "max_values = ansur_encoded_df.max()\n",
    "min_values = ansur_encoded_df.min()\n",
    "avg_values = ansur_encoded_df.mean()\n",
    "# print(\"max values are:\\n\", max_values)\n",
    "# print(\"min values are:\\n\", min_values)\n",
    "# print(\"avg values are:\\n\", avg_values)\n",
    "\n",
    "### Normalize all data\n",
    "# using StandardScaler, to represent each data point in terms of the aggregate characteristics for that collection of points\n",
    "ansur_scaler = StandardScaler().set_output(transform=\"pandas\")\n",
    "ansur_scaled_df = scaler.fit_transform(ansur_encoded_df)\n",
    "\n",
    "## 2. Print Covariances\n",
    "display(ansur_scaled_df.cov())\n",
    "\n",
    "## 3. Plot features most correlated to age, ear length and head circumference\n",
    "# features most correlated to age are ear.length, weight, ear.breadth, and hand.breadth\n",
    "# ear.length has strong correlation with different features: weight, hand.breadth, ear.breadth, stature, etc\n",
    "# the same applies to head circumference, with head.height, weight, foot.length\t, and foot.breadth being the most correlated features\n",
    "\n",
    "# plot age as a function of ear.length, weight, ear.breadth, and hand.breadth\n",
    "for feat in [\"ear.length\", \"weight\", \"ear.breadth\", \"hand.breadth\"]:\n",
    "  plt.plot(ansur_scaled_df[feat], ansur_scaled_df[\"age\"], marker=\"o\", color=\"r\", linestyle=\"\", alpha=0.4)\n",
    "  plt.xlabel(feat)\n",
    "  plt.ylabel(\"age\")\n",
    "  plt.show()\n",
    "\n",
    "# plot ear.length as a function of weight, hand.breadth, ear.breadth, stature\n",
    "for feat in [\"weight\", \"hand.breadth\", \"ear.breadth\", \"stature\"]:\n",
    "  plt.plot(ansur_scaled_df[feat], ansur_scaled_df[\"ear.length\"], marker=\"o\", color=\"b\", linestyle=\"\", alpha=0.4)\n",
    "  plt.xlabel(feat)\n",
    "  plt.ylabel(\"ear.length\")\n",
    "  plt.show()\n",
    "# these plots show a stronger, more discernible positive correlation between ear.length and the other features\n",
    "\n",
    "# plot head.circumference as a function of head.height, weight, foot.length, and foot.breadth\n",
    "for feat in [\"head.height\", \"weight\", \"foot.length\", \"foot.breadth\"]:\n",
    "  plt.plot(ansur_scaled_df[feat], ansur_scaled_df[\"head.circumference\"], marker=\"o\", color=\"g\", linestyle=\"\", alpha=0.4)\n",
    "  plt.xlabel(feat)\n",
    "  plt.ylabel(\"head.circumference\")\n",
    "  plt.show()\n",
    "# these plots also show a strong positive correlation between head.circumference and the other features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Does anything stand out about these graphs? Or the correlations?<br>\n",
    "Are correlations symmetric? Does the feature most correlated to ear length also have ear length as its most correlated pair?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "The plots for age should show a positive correlation between age and the other features, but the correlation is subtle so it's almost visually undiscernible in all cases except for ear.length, which shows a more pronounced positive correlation.\n",
    "\n",
    "In contrast, the plots for ear.length and head.circumference show a clearer, strong correlation between the variables and the respective correlated features.\n",
    "Overall, this suggests that age is not the stronger indicator when it comes to predicting the vaues for other features.\n",
    "\n",
    "Correlations are symmetric, meaning that the correlation between variable X and variable Y is identical to the correlation between variable Y and variable X. But this does not mean that the feature most correlated with a variable also has to have that variable as its most correlated pais. For example, the feature with which ear.length has the strongest correlation is weight. But weight shows more correlation with several other values than with ear.length, such as hand.breadth, foot.breadth, foot.length, and stature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "\n",
    "Now, we want to create a regression model to predict `head.circumference` from the data.\n",
    "\n",
    "From our [Week 07](https://github.com/PSAM-5020-2025F-A/WK07) notebook, we can create a regression model by following these steps:\n",
    "\n",
    "1. Load dataset (done! ðŸŽ‰)\n",
    "2. Encode label features as numbers (done! âš¡ï¸)\n",
    "3. Normalize the data (done! ðŸ¾)\n",
    "4. Separate the outcome variable and the input features\n",
    "5. Create a regression model using all features\n",
    "6. Run model on training data and measure error\n",
    "7. Plot predictions and interpret results\n",
    "8. Run model on test data, measure error, plot predictions, interpret results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Work on Regression Model here\n",
    "\n",
    "## Separate outcome variable and input features\n",
    "head_circumference = ansur_scaled_df[[\"head.circumference\"]]\n",
    "# using only 3 features that are most correlated to head.circumference, so that we can then plot and visualize the results more easily\n",
    "features = ansur_scaled_df[[\"head.height\", \"weight\", \"foot.length\", \"foot.breadth\"]]\n",
    "\n",
    "## Create a regression model\n",
    "head_circumference_model = LinearRegression().fit(features, head_circumference)\n",
    "\n",
    "## Measure error on training data\n",
    "predicted_head_circumference = head_circumference_model.predict(features)\n",
    "error = regression_error(head_circumference, predicted_head_circumference)\n",
    "print(\"error on training data:\", error)\n",
    "\n",
    "## Plot predictions and interpret results\n",
    "\n",
    "plt.plot(head_circumference, marker='o', linestyle='', alpha=0.3)\n",
    "plt.plot(predicted_head_circumference, color='r', marker='o', markersize='3', linestyle='', alpha=0.1)\n",
    "plt.ylabel(\"Head circumference (actual (blue) vs predicted (red))\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# another way to visualize how far off the model is from the actual data is to look at sorted lists of head circumferences\n",
    "# this lets us see if there are ranges where the model is wrong/right more often\n",
    "plt.plot(sorted(head_circumference.values), marker='o', linestyle='', alpha=0.3)\n",
    "plt.plot(sorted(predicted_head_circumference), color='r', marker='o', markersize='3', linestyle='', alpha=0.1)\n",
    "plt.ylabel(\"had circumference (actual (blue) vs predicted (red))\")\n",
    "plt.show()\n",
    "\n",
    "# and since there are more than 3 variables to map, we can just plot head circumference as a function of a few individual features\n",
    "# plot head.circumference vs head.height, weight, foot.length, foot.breadth\n",
    "for feat in [\"head.height\", \"weight\", \"foot.length\", \"foot.breadth\"]:\n",
    "  x = ansur_scaled_df[feat]\n",
    "  head_circumference_original = ansur_scaled_df[\"head.circumference\"]\n",
    "  head_circumference_predicted = predicted_head_circumference\n",
    "  # Plot the original and predicted head circumferences\n",
    "  plt.plot(x, head_circumference_original, marker='o', linestyle='', alpha=0.3)\n",
    "  plt.plot(x, head_circumference_predicted, color='r', marker='o', markersize='3', linestyle='', alpha=0.1)\n",
    "  plt.xlabel(feat)\n",
    "  plt.ylabel(\"head circumference\")\n",
    "  plt.show()\n",
    "\n",
    "# we can see that the predicted trend is correct, but there is a large error margin in the predictions\n",
    "# the middle ranges of the head circumference values seem to have less error than the extreme ends (seen in the sorted plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1692/4090785026.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mansur_test_encoded_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mansur_test_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mg_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mansur_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mansur_test_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gender\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mansur_test_encoded_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gender\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_vals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mansur_test_scaled_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mansur_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mansur_test_encoded_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4307\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ndim\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4308\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4309\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4310\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4311\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4312\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item_frame_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4313\u001b[0m         elif (\n",
      "\u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4357\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4358\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4360\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4361\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iset_not_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4363\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4364\u001b[0m                 \u001b[0;31m# list of lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4384\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4387\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4388\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Columns must be same length as key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4390\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4391\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0migetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "## Load Test Data\n",
    "ANSUR_TEST_FILE = \"https://raw.githubusercontent.com/PSAM-5020-2025F-A/5020-utils/main/datasets/json/ansur-test.json\"\n",
    "\n",
    "ansur_test_data = object_from_json_url(ANSUR_TEST_FILE)\n",
    "ansur_test_df = pd.json_normalize(ansur_test_data)\n",
    "\n",
    "ansur_test_encoded_df = ansur_test_df.copy()\n",
    "\n",
    "g_vals = ansur_encoder.transform(ansur_test_df[[\"gender\"]].values)\n",
    "ansur_test_encoded_df[[\"gender\"]] = g_vals\n",
    "\n",
    "ansur_test_scaled_df = ansur_scaler.transform(ansur_test_encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "## Run model on test data\n",
    "\n",
    "## Measure error on test data\n",
    "\n",
    "## Plot predictions and interpret results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "How well does your model perform?<br>\n",
    "How could you improve it?<br>\n",
    "Are there ranges of circumferences that don't get predicted well?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">EDIT THIS CELL WITH ANSWER</span>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPxe2qYxIG7EblrvD1C4Pmv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
